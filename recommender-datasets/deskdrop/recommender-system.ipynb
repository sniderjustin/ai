{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-04T14:49:53.690416Z","iopub.execute_input":"2022-05-04T14:49:53.690769Z","iopub.status.idle":"2022-05-04T14:49:53.725007Z","shell.execute_reply.started":"2022-05-04T14:49:53.690670Z","shell.execute_reply":"2022-05-04T14:49:53.724155Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Recommender System\n\nWritten using code from Gabriel Moreira's example notebook [here](https://www.kaggle.com/code/gspmoreira/recommender-systems-in-python-101/notebook).\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport scipy\nimport pandas as pd\nimport math\nimport random\nimport sklearn\nfrom nltk.corpus import stopwords\nfrom scipy.sparse import csr_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom scipy.sparse.linalg import svds\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:51:55.195023Z","iopub.execute_input":"2022-05-04T14:51:55.195323Z","iopub.status.idle":"2022-05-04T14:51:56.751195Z","shell.execute_reply.started":"2022-05-04T14:51:55.195288Z","shell.execute_reply":"2022-05-04T14:51:56.750256Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"articles_df = pd.read_csv('/kaggle/input/articles-sharing-reading-from-cit-deskdrop/shared_articles.csv')\narticles_df = articles_df[articles_df['eventType'] == 'CONTENT SHARED']\narticles_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:53:14.250200Z","iopub.execute_input":"2022-05-04T14:53:14.250504Z","iopub.status.idle":"2022-05-04T14:53:14.690586Z","shell.execute_reply.started":"2022-05-04T14:53:14.250471Z","shell.execute_reply":"2022-05-04T14:53:14.689719Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"interactions_df = pd.read_csv('/kaggle/input/articles-sharing-reading-from-cit-deskdrop/users_interactions.csv')\ninteractions_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:54:05.053510Z","iopub.execute_input":"2022-05-04T14:54:05.054410Z","iopub.status.idle":"2022-05-04T14:54:05.318697Z","shell.execute_reply.started":"2022-05-04T14:54:05.054349Z","shell.execute_reply":"2022-05-04T14:54:05.317835Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Assign value for different event types\nevent_type_strength = {\n   'VIEW': 1.0,\n   'LIKE': 2.0, \n   'BOOKMARK': 2.5, \n   'FOLLOW': 3.0,\n   'COMMENT CREATED': 4.0,  \n}\n\ninteractions_df['eventStrength'] = interactions_df['eventType'].apply(lambda x: event_type_strength[x])","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:55:33.400663Z","iopub.execute_input":"2022-05-04T14:55:33.401359Z","iopub.status.idle":"2022-05-04T14:55:33.435592Z","shell.execute_reply.started":"2022-05-04T14:55:33.401311Z","shell.execute_reply":"2022-05-04T14:55:33.434872Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Keep only users with at least 5 interactions to avoid cold start problem\nusers_interactions_count_df = interactions_df.groupby(['personId', 'contentId']).size().groupby('personId').size()\nprint('# users: %d' % len(users_interactions_count_df))\nusers_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['personId']]\nprint('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:56:30.760568Z","iopub.execute_input":"2022-05-04T14:56:30.760905Z","iopub.status.idle":"2022-05-04T14:56:30.794019Z","shell.execute_reply.started":"2022-05-04T14:56:30.760869Z","shell.execute_reply":"2022-05-04T14:56:30.793424Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print('# of interactions: %d' % len(interactions_df))\ninteractions_from_selected_users_df = interactions_df.merge(users_with_enough_interactions_df, \n               how = 'right',\n               left_on = 'personId',\n               right_on = 'personId')\nprint('# of interactions from users with at least 5 interactions: %d' % len(interactions_from_selected_users_df))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:57:23.813656Z","iopub.execute_input":"2022-05-04T14:57:23.814375Z","iopub.status.idle":"2022-05-04T14:57:23.850482Z","shell.execute_reply.started":"2022-05-04T14:57:23.814334Z","shell.execute_reply":"2022-05-04T14:57:23.849508Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Group person and content pairs. Provide event grouped event score\ndef smooth_user_preference(x):\n    return math.log(1+x, 2)\n    \ninteractions_full_df = interactions_from_selected_users_df \\\n                    .groupby(['personId', 'contentId'])['eventStrength'].sum() \\\n                    .apply(smooth_user_preference).reset_index()\nprint('# of unique user/item interactions: %d' % len(interactions_full_df))\ninteractions_full_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:59:52.999204Z","iopub.execute_input":"2022-05-04T14:59:52.999820Z","iopub.status.idle":"2022-05-04T14:59:53.063385Z","shell.execute_reply.started":"2022-05-04T14:59:52.999773Z","shell.execute_reply":"2022-05-04T14:59:53.062537Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Create train and test datasets\ninteractions_train_df, interactions_test_df = train_test_split(interactions_full_df,\n                                   stratify=interactions_full_df['personId'], \n                                   test_size=0.20,\n                                   random_state=42)\n\nprint('# interactions on Train set: %d' % len(interactions_train_df))\nprint('# interactions on Test set: %d' % len(interactions_test_df))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:01:40.086093Z","iopub.execute_input":"2022-05-04T15:01:40.086372Z","iopub.status.idle":"2022-05-04T15:01:40.133882Z","shell.execute_reply.started":"2022-05-04T15:01:40.086345Z","shell.execute_reply":"2022-05-04T15:01:40.133009Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Indexing by personId to speed up the searches during evaluation\ninteractions_full_indexed_df = interactions_full_df.set_index('personId')\ninteractions_train_indexed_df = interactions_train_df.set_index('personId')\ninteractions_test_indexed_df = interactions_test_df.set_index('personId')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:08:01.963706Z","iopub.execute_input":"2022-05-04T15:08:01.964043Z","iopub.status.idle":"2022-05-04T15:08:01.974064Z","shell.execute_reply.started":"2022-05-04T15:08:01.964007Z","shell.execute_reply":"2022-05-04T15:08:01.973367Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_items_interacted(person_id, interactions_df):\n    # Get the user's data and merge in the movie information.\n    interacted_items = interactions_df.loc[person_id]['contentId']\n    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:08:22.606443Z","iopub.execute_input":"2022-05-04T15:08:22.606912Z","iopub.status.idle":"2022-05-04T15:08:22.611103Z","shell.execute_reply.started":"2022-05-04T15:08:22.606863Z","shell.execute_reply":"2022-05-04T15:08:22.610234Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#Top-N accuracy metrics consts\nEVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n\nclass ModelEvaluator:\n\n\n    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n        interacted_items = get_items_interacted(person_id, interactions_full_indexed_df)\n        all_items = set(articles_df['contentId'])\n        non_interacted_items = all_items - interacted_items\n\n        random.seed(seed)\n        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n        return set(non_interacted_items_sample)\n\n    def _verify_hit_top_n(self, item_id, recommended_items, topn):        \n            try:\n                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n            except:\n                index = -1\n            hit = int(index in range(0, topn))\n            return hit, index\n\n    def evaluate_model_for_user(self, model, person_id):\n        #Getting the items in test set\n        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n        if type(interacted_values_testset['contentId']) == pd.Series:\n            person_interacted_items_testset = set(interacted_values_testset['contentId'])\n        else:\n            person_interacted_items_testset = set([int(interacted_values_testset['contentId'])])  \n        interacted_items_count_testset = len(person_interacted_items_testset) \n\n        #Getting a ranked recommendation list from a model for a given user\n        person_recs_df = model.recommend_items(person_id, \n                                               items_to_ignore=get_items_interacted(person_id, \n                                                                                    interactions_train_indexed_df), \n                                               topn=10000000000)\n\n        hits_at_5_count = 0\n        hits_at_10_count = 0\n        #For each item the user has interacted in test set\n        for item_id in person_interacted_items_testset:\n            #Getting a random sample (100) items the user has not interacted \n            #(to represent items that are assumed to be no relevant to the user)\n            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, \n                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \n                                                                          seed=item_id%(2**32))\n\n            #Combining the current interacted item with the 100 random items\n            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n\n            #Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n            valid_recs_df = person_recs_df[person_recs_df['contentId'].isin(items_to_filter_recs)]                    \n            valid_recs = valid_recs_df['contentId'].values\n            #Verifying if the current interacted item is among the Top-N recommended items\n            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n            hits_at_5_count += hit_at_5\n            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n            hits_at_10_count += hit_at_10\n\n        #Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n        #when mixed with a set of non-relevant items\n        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n\n        person_metrics = {'hits@5_count':hits_at_5_count, \n                          'hits@10_count':hits_at_10_count, \n                          'interacted_count': interacted_items_count_testset,\n                          'recall@5': recall_at_5,\n                          'recall@10': recall_at_10}\n        return person_metrics\n\n    def evaluate_model(self, model):\n        #print('Running evaluation for users')\n        people_metrics = []\n        for idx, person_id in enumerate(list(interactions_test_indexed_df.index.unique().values)):\n            #if idx % 100 == 0 and idx > 0:\n            #    print('%d users processed' % idx)\n            person_metrics = self.evaluate_model_for_user(model, person_id)  \n            person_metrics['_person_id'] = person_id\n            people_metrics.append(person_metrics)\n        print('%d users processed' % idx)\n\n        detailed_results_df = pd.DataFrame(people_metrics) \\\n                            .sort_values('interacted_count', ascending=False)\n        \n        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n        \n        global_metrics = {'modelName': model.get_model_name(),\n                          'recall@5': global_recall_at_5,\n                          'recall@10': global_recall_at_10}    \n        return global_metrics, detailed_results_df\n    \nmodel_evaluator = ModelEvaluator()    ","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:09:31.626285Z","iopub.execute_input":"2022-05-04T15:09:31.626720Z","iopub.status.idle":"2022-05-04T15:09:31.647703Z","shell.execute_reply.started":"2022-05-04T15:09:31.626673Z","shell.execute_reply":"2022-05-04T15:09:31.646629Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#Computes the most popular items\nitem_popularity_df = interactions_full_df.groupby('contentId')['eventStrength'].sum().sort_values(ascending=False).reset_index()\nitem_popularity_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:10:12.087308Z","iopub.execute_input":"2022-05-04T15:10:12.087747Z","iopub.status.idle":"2022-05-04T15:10:12.103121Z","shell.execute_reply.started":"2022-05-04T15:10:12.087707Z","shell.execute_reply":"2022-05-04T15:10:12.102252Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Create Popularity Model\n\nFind and reccomend the most popular items. \n\nDoes not customize reccomendations to the user. ","metadata":{}},{"cell_type":"code","source":"class PopularityRecommender:\n    \n    MODEL_NAME = 'Popularity'\n    \n    def __init__(self, popularity_df, items_df=None):\n        self.popularity_df = popularity_df\n        self.items_df = items_df\n        \n    def get_model_name(self):\n        return self.MODEL_NAME\n        \n    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n        # Recommend the more popular items that the user hasn't seen yet.\n        recommendations_df = self.popularity_df[~self.popularity_df['contentId'].isin(items_to_ignore)] \\\n                               .sort_values('eventStrength', ascending = False) \\\n                               .head(topn)\n\n        if verbose:\n            if self.items_df is None:\n                raise Exception('\"items_df\" is required in verbose mode')\n\n            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n                                                          left_on = 'contentId', \n                                                          right_on = 'contentId')[['eventStrength', 'contentId', 'title', 'url', 'lang']]\n\n\n        return recommendations_df\n    \npopularity_model = PopularityRecommender(item_popularity_df, articles_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:10:25.448267Z","iopub.execute_input":"2022-05-04T15:10:25.448791Z","iopub.status.idle":"2022-05-04T15:10:25.457157Z","shell.execute_reply.started":"2022-05-04T15:10:25.448750Z","shell.execute_reply":"2022-05-04T15:10:25.456566Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print('Evaluating Popularity recommendation model...')\npop_global_metrics, pop_detailed_results_df = model_evaluator.evaluate_model(popularity_model)\nprint('\\nGlobal metrics:\\n%s' % pop_global_metrics)\npop_detailed_results_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:10:59.436249Z","iopub.execute_input":"2022-05-04T15:10:59.437013Z","iopub.status.idle":"2022-05-04T15:11:14.971289Z","shell.execute_reply.started":"2022-05-04T15:10:59.436970Z","shell.execute_reply":"2022-05-04T15:11:14.970442Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Here we perform the evaluation of the Popularity model, according to the method described above.\nIt achieved the Recall@5 of 0.2417, which means that about 24% of interacted items in test set were ranked by Popularity model among the top-5 items (from lists with 100 random items). And Recall@10 was even higher (37%), as expected.\nIt might be surprising to you that usually Popularity models could perform so well!","metadata":{}},{"cell_type":"markdown","source":"## Create a Content-Based Filtering Model\n\nWe recommend items similar to other items the user has interacted with in the past. This approach helps to avoid the cold-start problem. \n\nWe use the TF-IDF to convert unstructured text into a vectors. We can then compute the similarity between articles by using our vectors. ","metadata":{}},{"cell_type":"code","source":"#Ignoring stopwords (words with no semantics) from English and Portuguese (as we have a corpus with mixed languages)\nstopwords_list = stopwords.words('english') + stopwords.words('portuguese')\n\n#Trains a model whose vectors size is 5000, composed by the main unigrams and bigrams found in the corpus, ignoring stopwords\nvectorizer = TfidfVectorizer(analyzer='word',\n                     ngram_range=(1, 2),\n                     min_df=0.003,\n                     max_df=0.5,\n                     max_features=5000,\n                     stop_words=stopwords_list)\n\nitem_ids = articles_df['contentId'].tolist()\ntfidf_matrix = vectorizer.fit_transform(articles_df['title'] + \"\" + articles_df['text'])\ntfidf_feature_names = vectorizer.get_feature_names_out()\ntfidf_matrix","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:31:27.787727Z","iopub.execute_input":"2022-05-04T15:31:27.788612Z","iopub.status.idle":"2022-05-04T15:31:38.384796Z","shell.execute_reply.started":"2022-05-04T15:31:27.788571Z","shell.execute_reply":"2022-05-04T15:31:38.383987Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def get_item_profile(item_id):\n    idx = item_ids.index(item_id)\n    item_profile = tfidf_matrix[idx:idx+1]\n    return item_profile\n\ndef get_item_profiles(ids):\n    item_profiles_list = [get_item_profile(x) for x in ids]\n    item_profiles = scipy.sparse.vstack(item_profiles_list)\n    return item_profiles\n\ndef build_users_profile(person_id, interactions_indexed_df):\n    interactions_person_df = interactions_indexed_df.loc[person_id]\n    user_item_profiles = get_item_profiles(interactions_person_df['contentId'])\n    \n    user_item_strengths = np.array(interactions_person_df['eventStrength']).reshape(-1,1)\n    #Weighted average of item profiles by the interactions strength\n    user_item_strengths_weighted_avg = np.sum(user_item_profiles.multiply(user_item_strengths), axis=0) / np.sum(user_item_strengths)\n    user_profile_norm = sklearn.preprocessing.normalize(user_item_strengths_weighted_avg)\n    return user_profile_norm\n\ndef build_users_profiles(): \n    interactions_indexed_df = interactions_train_df[interactions_train_df['contentId'] \\\n                                                   .isin(articles_df['contentId'])].set_index('personId')\n    user_profiles = {}\n    for person_id in interactions_indexed_df.index.unique():\n        user_profiles[person_id] = build_users_profile(person_id, interactions_indexed_df)\n    return user_profiles","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:33:05.643639Z","iopub.execute_input":"2022-05-04T15:33:05.643925Z","iopub.status.idle":"2022-05-04T15:33:05.653409Z","shell.execute_reply.started":"2022-05-04T15:33:05.643896Z","shell.execute_reply":"2022-05-04T15:33:05.652526Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"user_profiles = build_users_profiles()\nlen(user_profiles)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:33:22.364440Z","iopub.execute_input":"2022-05-04T15:33:22.365164Z","iopub.status.idle":"2022-05-04T15:33:29.014183Z","shell.execute_reply.started":"2022-05-04T15:33:22.365113Z","shell.execute_reply":"2022-05-04T15:33:29.013392Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"myprofile = user_profiles[-1479311724257856983]\nprint(myprofile.shape)\npd.DataFrame(sorted(zip(tfidf_feature_names, \n                        user_profiles[-1479311724257856983].flatten().tolist()), key=lambda x: -x[1])[:20],\n             columns=['token', 'relevance'])","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:34:20.313759Z","iopub.execute_input":"2022-05-04T15:34:20.314356Z","iopub.status.idle":"2022-05-04T15:34:20.334493Z","shell.execute_reply.started":"2022-05-04T15:34:20.314318Z","shell.execute_reply":"2022-05-04T15:34:20.333656Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class ContentBasedRecommender:\n    \n    MODEL_NAME = 'Content-Based'\n    \n    def __init__(self, items_df=None):\n        self.item_ids = item_ids\n        self.items_df = items_df\n        \n    def get_model_name(self):\n        return self.MODEL_NAME\n        \n    def _get_similar_items_to_user_profile(self, person_id, topn=1000):\n        #Computes the cosine similarity between the user profile and all item profiles\n        cosine_similarities = cosine_similarity(user_profiles[person_id], tfidf_matrix)\n        #Gets the top similar items\n        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n        #Sort the similar items by similarity\n        similar_items = sorted([(item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n        return similar_items\n        \n    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n        similar_items = self._get_similar_items_to_user_profile(user_id)\n        #Ignores items the user has already interacted\n        similar_items_filtered = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))\n        \n        recommendations_df = pd.DataFrame(similar_items_filtered, columns=['contentId', 'recStrength']) \\\n                                    .head(topn)\n\n        if verbose:\n            if self.items_df is None:\n                raise Exception('\"items_df\" is required in verbose mode')\n\n            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n                                                          left_on = 'contentId', \n                                                          right_on = 'contentId')[['recStrength', 'contentId', 'title', 'url', 'lang']]\n\n\n        return recommendations_df\n    \ncontent_based_recommender_model = ContentBasedRecommender(articles_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:34:51.946492Z","iopub.execute_input":"2022-05-04T15:34:51.947160Z","iopub.status.idle":"2022-05-04T15:34:51.958707Z","shell.execute_reply.started":"2022-05-04T15:34:51.947120Z","shell.execute_reply":"2022-05-04T15:34:51.957809Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print('Evaluating Content-Based Filtering model...')\ncb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model)\nprint('\\nGlobal metrics:\\n%s' % cb_global_metrics)\ncb_detailed_results_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:35:15.407171Z","iopub.execute_input":"2022-05-04T15:35:15.407834Z","iopub.status.idle":"2022-05-04T15:35:39.030166Z","shell.execute_reply.started":"2022-05-04T15:35:15.407790Z","shell.execute_reply":"2022-05-04T15:35:39.029347Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"With personalized recommendations of content-based filtering model, we have a Recall@5 to about 0.162, which means that about 16% of interacted items in test set were ranked by this model among the top-5 items (from lists with 100 random items). And Recall@10 was 0.261 (52%). The lower performance of the Content-Based model compared to the Popularity model may indicate that users are not that fixed in content very similar to their previous reads.","metadata":{}},{"cell_type":"code","source":"# TODO: RESUME HERE with Collaborative Filtering Model","metadata":{},"execution_count":null,"outputs":[]}]}